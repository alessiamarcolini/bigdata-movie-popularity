{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets import HADOOP_USER_NAME, SPARK_URI, HADOOP_NAMENODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(SPARK_URI)\n",
    "sparkSession = (\n",
    "    SparkSession.builder.appName(\"example-pyspark-read-and-write1\")\n",
    "    .config(\"spark.hadoop.dfs.client.use.datanode.hostname\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from hdfs\n",
    "opusdata = sparkSession.read.csv(\n",
    "    f\"hdfs://{HADOOP_NAMENODE}:8020/raw/opusdata.csv\", header=True, inferSchema=True\n",
    ")\n",
    "opusdata.show()\n",
    "\n",
    "# sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_filter_0 = opusdata.filter(opusdata[\"production_budget\"] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_filter_0 = opusdata_filter_0.filter(\n",
    "    opusdata_filter_0[\"domestic_box_office\"] != 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_filter_0 = opusdata_filter_0.filter(\n",
    "    opusdata_filter_0[\"international_box_office\"] != 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_dropped = opusdata_filter_0.drop(\n",
    "    \"movie_odid\", \"running_time\", \"production_method\", \"creative_type\", \"source\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_years = opusdata_dropped.filter(opusdata_dropped[\"production_year\"] >= 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_distinct = opusdata_years.dropDuplicates([\"movie_name\", \"production_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_total_box_office = opusdata_distinct.withColumn(\n",
    "    \"total_box_office\",\n",
    "    opusdata_distinct[\"domestic_box_office\"]\n",
    "    + opusdata_distinct[\"international_box_office\"],\n",
    ").drop(\"domestic_box_office\", \"international_box_office\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_droppped_na = opusdata_total_box_office.na.drop(subset=[\"genre\", \"sequel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_droppped_na.coalesce(1).write.mode(\"overwrite\").option('header',True).csv(\n",
    "    f\"hdfs://{HADOOP_NAMENODE}:8020/processed/opusdata_00.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bigdata)",
   "language": "python",
   "name": "bigdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
