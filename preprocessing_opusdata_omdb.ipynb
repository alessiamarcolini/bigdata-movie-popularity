{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets import OMDB_API_KEY, HADOOP_USER_NAME, SPARK_URI, HADOOP_NAMENODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HADOOP_USER_NAME'] = HADOOP_USER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "from hdfs import InsecureClient\n",
    "import omdb\n",
    "from omdb import OMDBClient\n",
    "import pyspark.sql.types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_hdfs = InsecureClient(f'http://{HADOOP_NAMENODE}:50070', user=HADOOP_USER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preprocessed opusdata filename\n",
    "hdfs_path = \"/processed/opusdata_00.csv\"\n",
    "\n",
    "filename = [f for f in client_hdfs.list(hdfs_path) if f.endswith('.csv')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(SPARK_URI)\n",
    "sparkSession = (\n",
    "    SparkSession.builder.appName(\"example-pyspark-read-and-write\")\n",
    "    .config(\"spark.hadoop.dfs.client.use.datanode.hostname\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from hdfs\n",
    "opusdata = sparkSession.read.csv(\n",
    "    f\"hdfs://{HADOOP_NAMENODE}:8020{hdfs_path}/{filename}\", header=True, inferSchema=True\n",
    ")\n",
    "\n",
    "\n",
    "# sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb.set_default('apikey', OMDB_API_KEY)\n",
    "client = OMDBClient(apikey=OMDB_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_flat_fields = ['runtime', 'director', 'actors', 'country', 'awards', 'imdb_votes', 'imdb_id']\n",
    "requested_nested_fields = {'ratings': ['Internet Movie Database', 'Rotten Tomatoes', 'Metacritic']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_source(source):\n",
    "    return '_'.join(source.split()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_schema(requested_flat_fields, requested_nested_fields):\n",
    "    schema = []\n",
    "    for key in requested_flat_fields:\n",
    "        schema.append(t.StructField(key, t.StringType(), True))\n",
    "    for key, values in requested_nested_fields.items():\n",
    "        for value in values:\n",
    "            schema.append(t.StructField(f'{key}_{format_source(value)}', t.StringType(), True))\n",
    "            \n",
    "    return t.StructType(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = construct_schema(requested_flat_fields, requested_nested_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=schema)\n",
    "def omdb_data(arguments):\n",
    "\n",
    "    movie_name, year = arguments\n",
    "    print(movie_name)\n",
    "    result = client.get(title=movie_name, year=year, fullplot=True, tomatoes=True)\n",
    "    \n",
    "    result_to_keep = {}\n",
    "    \n",
    "    for key in requested_flat_fields:\n",
    "        result_to_keep[key] = result.get(key, None)\n",
    "        \n",
    "    for nested_field in requested_nested_fields:\n",
    "        requested_nested_list = requested_nested_fields[nested_field]\n",
    "        nested_list = result.get(nested_field, None)\n",
    "        \n",
    "        if nested_list:\n",
    "            for nested_dict in nested_list:\n",
    "                source = nested_dict.get('source', None)\n",
    "\n",
    "                if source:\n",
    "                    value = nested_dict.get('value', None)\n",
    "                    \n",
    "                    if source in requested_nested_list:\n",
    "\n",
    "                        source_formatted = format_source(source)\n",
    "                        key = f'{nested_field}_{source_formatted}'\n",
    "\n",
    "                        result_to_keep[key] = value\n",
    "                        \n",
    "            requested_sources = requested_nested_fields[nested_field]\n",
    "            for requested_source in requested_sources:\n",
    "                source_formatted = format_source(requested_source)\n",
    "                key = f'{nested_field}_{source_formatted}'\n",
    "                if not key in result_to_keep:\n",
    "                    result_to_keep[key] = None\n",
    "                    \n",
    "        else:\n",
    "            requested_sources = requested_nested_fields[nested_field]\n",
    "            for requested_source in requested_sources:\n",
    "                source_formatted = format_source(requested_source)\n",
    "                key = f'{nested_field}_{source_formatted}'\n",
    "                result_to_keep[key] = None\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "    #print(result_to_keep.keys(), result_to_keep.values())\n",
    "    return t.Row(*list(result_to_keep.keys()))(*list(result_to_keep.values()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_omdb = opusdata.withColumn(\n",
    "    \"omdb_data\", F.explode(F.array(omdb_data(F.array(\"movie_name\", \"production_year\"))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_fields_name = [field.name for field in opusdata.schema.fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_ombd = opusdata_omdb.select(*opusdata_fields_name, 'omdb_data.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_ombd_id_not_null = opusdata_ombd.na.drop(\n",
    "    subset=[\n",
    "        \"imdb_id\",\n",
    "        \"ratings_internet_movie_database\",\n",
    "        \"ratings_rotten_tomatoes\",\n",
    "        \"ratings_metacritic\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_ombd_no_id_duplicated = opusdata_ombd_id_not_null.dropDuplicates(['imdb_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=t.IntegerType())\n",
    "def general_awards_by_keyword(awards_str, keyword):\n",
    "    n_nominations = awards_str.split(keyword)[0].split()[-1]\n",
    "    try:\n",
    "        n_nominations_int = int(n_nominations)\n",
    "    except ValueError as e:\n",
    "        n_nominations_int = 0\n",
    "    return n_nominations_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_general = ['nomination', 'win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_name = ['golden globe', 'oscar', 'bafta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=t.IntegerType())\n",
    "def won_by_keyword(awards_str, award_name):\n",
    "    awards_str = awards_str.lower()\n",
    "    \n",
    "    try:\n",
    "        won_or_nominated = awards_str.split(award_name)[0].split()[-2]\n",
    "        if won_or_nominated == \"won\":\n",
    "            n_won = int(awards_str.split(award_name)[0].split()[-1])\n",
    "        else:\n",
    "            n_won = 0\n",
    "    except IndexError as e:\n",
    "        n_won = 0\n",
    "\n",
    "    return n_won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=t.IntegerType())\n",
    "def nominated_by_keyword(awards_str, award_name):\n",
    "    awards_str = awards_str.lower()\n",
    "   \n",
    "    try:\n",
    "        won_or_nominated = awards_str.split(award_name)[0].split()[-2]\n",
    "        if won_or_nominated == \"for\":\n",
    "            n_nominated = int(awards_str.split(award_name)[0].split()[-1])\n",
    "        else:\n",
    "            n_nominated = 0\n",
    "    except IndexError as e:\n",
    "        n_nominated = 0\n",
    "\n",
    "    return n_nominated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_awards_categorized = opusdata_ombd_no_id_duplicated\n",
    "for general_keyword in keywords_general:\n",
    "    opusdata_awards_categorized = opusdata_awards_categorized.withColumn(\n",
    "        f'{general_keyword}s', general_awards_by_keyword(\"awards\", F.lit(general_keyword))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for award_name in awards_name:\n",
    "    award_name_formatted = '_'.join(award_name.split())\n",
    "    opusdata_awards_categorized = opusdata_awards_categorized.withColumn(\n",
    "        f'won_{award_name_formatted}s', won_by_keyword(\"awards\", F.lit(award_name))\n",
    "    )\n",
    "    opusdata_awards_categorized = opusdata_awards_categorized.withColumn(\n",
    "        f'nominated_{award_name_formatted}s', nominated_by_keyword(\"awards\", F.lit(award_name))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_awards_categorized = opusdata_awards_categorized.drop('awards')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale rankings [0..1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale imdb ratings\n",
    "opusdata_scaled_ratings = opusdata_awards_categorized.withColumn(\n",
    "    \"ratings_internet_movie_database\", F.split(F.col(\"ratings_internet_movie_database\"), \"/\").cast(\"array<float>\") \\\n",
    "   \n",
    ")\n",
    "opusdata_scaled_ratings = opusdata_scaled_ratings.withColumn(\n",
    "    \"ratings_internet_movie_database\", F.col(\"ratings_internet_movie_database\")[0] / 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale rotten tomatoes ratings\n",
    "opusdata_scaled_ratings = opusdata_scaled_ratings.withColumn(\n",
    "    \"ratings_rotten_tomatoes\", F.split(F.col(\"ratings_rotten_tomatoes\"), \"%\").cast(\"array<int>\") \\\n",
    "   \n",
    ")\n",
    "opusdata_scaled_ratings = opusdata_scaled_ratings.withColumn(\n",
    "    \"ratings_rotten_tomatoes\", F.col(\"ratings_rotten_tomatoes\")[0] / 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale metacritic ratings\n",
    "opusdata_scaled_ratings = opusdata_scaled_ratings.withColumn(\n",
    "    \"ratings_metacritic\", F.split(F.col(\"ratings_metacritic\"), \"/\").cast(\"array<int>\") \\\n",
    "   \n",
    ")\n",
    "opusdata_scaled_ratings = opusdata_scaled_ratings.withColumn(\n",
    "    \"ratings_metacritic\", F.col(\"ratings_metacritic\")[0] / 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove comma from imdb_votes\n",
    "opusdata_votes = opusdata_scaled_ratings.withColumn(\n",
    "    \"imdb_votes\", F.regexp_replace(\"imdb_votes\", \",\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_actors = set()\n",
    "\n",
    "for i, row in enumerate(opusdata_votes.rdd.collect()):\n",
    "    actors = row['actors']\n",
    "    unique_actors.update([a.strip().lower() for a in actors.split(',')])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_id_dict = {actor: i for i, actor in enumerate(unique_actors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_actors = t.StructType([\n",
    "    t.StructField('actor_id_0', t.IntegerType(), True),\n",
    "    t.StructField('actor_id_1', t.IntegerType(), True),\n",
    "    t.StructField('actor_id_2', t.IntegerType(), True),\n",
    "    t.StructField('actor_id_3', t.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=schema_actors)\n",
    "def encode_authors(actors_str):\n",
    "    actors = [a.strip().lower() for a in actors_str.split(',')]\n",
    "    \n",
    "    ids = []\n",
    "    for a in actors:\n",
    "        ids.append(actors_id_dict[a])\n",
    "    \n",
    "    ids = sorted(ids) + (4-len(ids))*[None]\n",
    "        \n",
    "    return t.Row('actor_id_0', 'actor_id_1', 'actor_id_2', 'actor_id_3')(*ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_actors = opusdata_votes.withColumn(\n",
    "    \"actors_ids\", F.explode(F.array(encode_authors(\"actors\")))\n",
    ")\n",
    "\n",
    "opusdata_fields_name = [\n",
    "    field.name\n",
    "    for field in opusdata_actors.schema.fields\n",
    "    if field.name != \"actors_ids\" and field.name != \"actors\"\n",
    "]\n",
    "opusdata_actors = opusdata_actors.select(*opusdata_fields_name, \"actors_ids.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime - remove \"min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_runtime = opusdata_actors.withColumn(\n",
    "    \"runtime\", F.split(F.col(\"runtime\"), \" \").cast(\"array<string>\")\n",
    ")\n",
    "opusdata_runtime = opusdata_runtime.withColumn(\"runtime\", F.col(\"runtime\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only first country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_first_country = opusdata_runtime.withColumn(\n",
    "    \"country\", F.split(F.col(\"country\"), \",\").cast(\"array<string>\") \\\n",
    "   \n",
    ")\n",
    "opusdata_first_country = opusdata_first_country.withColumn(\n",
    "    \"country\", F.col(\"country\")[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only first director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_first_director = opusdata_first_country.withColumn(\n",
    "    \"director\", F.split(F.col(\"director\"), \",\").cast(\"array<string>\") \\\n",
    "   \n",
    ")\n",
    "opusdata_first_director = opusdata_first_director.withColumn(\n",
    "    \"director\", F.col(\"director\")[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get \"success\" [1]\n",
    "[1] _Rhee, Travis Ginmu, and Farhana Zulkernine. \"Predicting movie box office profitability: A neural network approach.\" 2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 2016._\n",
    "\n",
    "Profit = (1⁄2 * total_box_office) – production_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=t.IntegerType())\n",
    "def success(arguments):\n",
    "    total_box_office, production_budget = arguments\n",
    "    \n",
    "    profit = (0.5 * total_box_office) - production_budget\n",
    "    profit_censored = 1 if profit > 0 else 0\n",
    "    return profit_censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_success = opusdata_first_director.withColumn(\n",
    "    \"success\", success(F.array(\"total_box_office\", \"production_budget\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opusdata_success.write.csv('opusdata_omdb2.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opusdata_success.repartition(1).write.mode(\"overwrite\").option('header',True).csv(\n",
    "    f\"hdfs://{HADOOP_NAMENODE}:8020/processed/opusdata_omdb_00.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bigdata)",
   "language": "python",
   "name": "bigdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
